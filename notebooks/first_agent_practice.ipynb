{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5a93fb43",
   "metadata": {},
   "source": [
    "# 🤖 Building Your First Agent - Practice Notebook\n",
    "\n",
    "This notebook guides you through building a Reflection Agent step-by-step.\n",
    "\n",
    "**What you'll build:** An agent that answers questions and improves its answers through self-reflection.\n",
    "\n",
    "## Setup\n",
    "\n",
    "Run the cell below to import what we need."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ccf5d0ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Imports complete!\n"
     ]
    }
   ],
   "source": [
    "# Imports\n",
    "from datetime import datetime\n",
    "from typing import List, Dict, Optional\n",
    "import json\n",
    "\n",
    "print(\"✅ Imports complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f0e1040",
   "metadata": {},
   "source": [
    "## Part 1: Build Memory Systems\n",
    "\n",
    "First, let's create the memory components.\n",
    "\n",
    "### Short-Term Memory\n",
    "This holds the current context (last few actions)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "23cb18a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Short-term memory: [{'step': 1, 'action': 'search'}, {'step': 2, 'action': 'read'}]\n",
      "✅ Short-term memory works!\n"
     ]
    }
   ],
   "source": [
    "class ShortTermMemory:\n",
    "    \"\"\"Working memory for current task\"\"\"\n",
    "    \n",
    "    def __init__(self, max_size: int = 5):\n",
    "        self.max_size = max_size\n",
    "        self.context = []\n",
    "    \n",
    "    def add(self, item: Dict):\n",
    "        \"\"\"Add item to working memory\"\"\"\n",
    "        self.context.append(item)\n",
    "        \n",
    "        # Keep only recent items\n",
    "        if len(self.context) > self.max_size:\n",
    "            self.context = self.context[-self.max_size:]\n",
    "    \n",
    "    def get(self) -> List[Dict]:\n",
    "        \"\"\"Get current context\"\"\"\n",
    "        return self.context\n",
    "    \n",
    "    def clear(self):\n",
    "        \"\"\"Clear working memory\"\"\"\n",
    "        self.context = []\n",
    "\n",
    "# Test it\n",
    "stm = ShortTermMemory(max_size=3)\n",
    "stm.add({\"step\": 1, \"action\": \"search\"})\n",
    "stm.add({\"step\": 2, \"action\": \"read\"})\n",
    "print(\"Short-term memory:\", stm.get())\n",
    "print(\"✅ Short-term memory works!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "823d278c",
   "metadata": {},
   "source": [
    "### Episodic Memory\n",
    "This logs all actions - like a diary of what the agent did."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "307f1617",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episodic memory:\n",
      "Total actions: 2\n",
      "  - perceive: 1\n",
      "  - plan: 1\n",
      "\n",
      "✅ Episodic memory works!\n"
     ]
    }
   ],
   "source": [
    "class EpisodicMemory:\n",
    "    \"\"\"Log of all actions and results\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.episodes = []\n",
    "    \n",
    "    def log(self, action_type: str, details: Dict):\n",
    "        \"\"\"Log an action\"\"\"\n",
    "        episode = {\n",
    "            \"timestamp\": datetime.now().isoformat(),\n",
    "            \"action\": action_type,\n",
    "            \"details\": details\n",
    "        }\n",
    "        self.episodes.append(episode)\n",
    "    \n",
    "    def get_history(self) -> List[Dict]:\n",
    "        \"\"\"Get all episodes\"\"\"\n",
    "        return self.episodes\n",
    "    \n",
    "    def get_summary(self) -> str:\n",
    "        \"\"\"Summarize the session\"\"\"\n",
    "        summary = f\"Total actions: {len(self.episodes)}\\n\"\n",
    "        \n",
    "        action_counts = {}\n",
    "        for ep in self.episodes:\n",
    "            action = ep[\"action\"]\n",
    "            action_counts[action] = action_counts.get(action, 0) + 1\n",
    "        \n",
    "        for action, count in action_counts.items():\n",
    "            summary += f\"  - {action}: {count}\\n\"\n",
    "        \n",
    "        return summary\n",
    "\n",
    "# Test it\n",
    "em = EpisodicMemory()\n",
    "em.log(\"perceive\", {\"context\": \"ready\"})\n",
    "em.log(\"plan\", {\"action\": \"search\"})\n",
    "print(\"Episodic memory:\")\n",
    "print(em.get_summary())\n",
    "print(\"✅ Episodic memory works!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db5c5479",
   "metadata": {},
   "source": [
    "## Part 2: Create Mock LLM\n",
    "\n",
    "We'll use a mock LLM so you can test without API keys.\n",
    "Later you can replace this with real OpenAI/Anthropic calls."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ce2a68c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Mock LLM ready!\n"
     ]
    }
   ],
   "source": [
    "class MockLLM:\n",
    "    \"\"\"Mock LLM for testing without API keys\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.call_count = 0\n",
    "    \n",
    "    def complete(self, prompt: str) -> str:\n",
    "        \"\"\"Generate a response (simulated)\"\"\"\n",
    "        self.call_count += 1\n",
    "        print(f\"\\n💭 [LLM CALL #{self.call_count}]\")\n",
    "        print(f\"Prompt preview: {prompt[:80]}...\")\n",
    "        \n",
    "        # Simulate responses\n",
    "        if \"critique\" in prompt.lower() or \"evaluate\" in prompt.lower():\n",
    "            if self.call_count <= 3:\n",
    "                return \"Quality: 7/10. The answer is decent but could be more detailed.\"\n",
    "            else:\n",
    "                return \"Quality: 9/10. Excellent! Clear and comprehensive.\"\n",
    "        else:\n",
    "            if \"difference\" in prompt.lower() and \"agent\" in prompt.lower():\n",
    "                if self.call_count == 1:\n",
    "                    return \"A language model responds to prompts. An AI agent can autonomously pursue goals using tools.\"\n",
    "                else:\n",
    "                    return \"\"\"A language model is reactive - it responds to prompts but doesn't take actions.\n",
    "\n",
    "An AI agent is proactive and autonomous:\n",
    "1. Has goals it works toward\n",
    "2. Plans multi-step solutions  \n",
    "3. Uses tools (search, APIs, code execution)\n",
    "4. Maintains memory\n",
    "5. Learns through reflection\n",
    "\n",
    "Example: ChatGPT is a model. An agent that searches, reads papers, and writes reports is an agent.\"\"\"\n",
    "            else:\n",
    "                return f\"This is a simulated answer for: {prompt[:100]}...\"\n",
    "\n",
    "llm = MockLLM()\n",
    "print(\"✅ Mock LLM ready!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b2a6db3",
   "metadata": {},
   "source": [
    "## Part 3: Build the Reflection Agent\n",
    "\n",
    "Now the main part - the agent with the full loop!\n",
    "\n",
    "This is the complete agent that uses:\n",
    "- The agent loop (Perceive → Plan → Act → Reflect)\n",
    "- Memory systems we just built\n",
    "- Mock LLM to generate responses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a860c49c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ ReflectionAgent class created!\n"
     ]
    }
   ],
   "source": [
    "class ReflectionAgent:\n",
    "    \"\"\"Agent that improves answers through self-reflection\"\"\"\n",
    "    \n",
    "    def __init__(self, llm, max_iterations: int = 3):\n",
    "        self.llm = llm\n",
    "        self.max_iterations = max_iterations\n",
    "        \n",
    "        # Memory systems\n",
    "        self.short_term = ShortTermMemory()\n",
    "        self.episodic = EpisodicMemory()\n",
    "        \n",
    "        # Agent state\n",
    "        self.current_question = None\n",
    "        self.current_answer = None\n",
    "        self.iteration = 0\n",
    "        self.satisfied = False\n",
    "    \n",
    "    def run(self, question: str) -> str:\n",
    "        \"\"\"Main agent loop\"\"\"\n",
    "        self.current_question = question\n",
    "        self.iteration = 0\n",
    "        self.satisfied = False\n",
    "        \n",
    "        print(f\"\\n{'='*60}\")\n",
    "        print(f\"🎯 QUESTION: {question}\")\n",
    "        print(f\"{'='*60}\")\n",
    "        \n",
    "        while not self.satisfied and self.iteration < self.max_iterations:\n",
    "            self.iteration += 1\n",
    "            print(f\"\\n{'─'*60}\")\n",
    "            print(f\"🔄 ITERATION {self.iteration}/{self.max_iterations}\")\n",
    "            print(f\"{'─'*60}\")\n",
    "            \n",
    "            # THE AGENT LOOP\n",
    "            context = self.perceive()\n",
    "            action = self.plan(context)\n",
    "            result = self.act(action)\n",
    "            self.reflect(result)\n",
    "        \n",
    "        print(f\"\\n{'='*60}\")\n",
    "        print(f\"✅ FINAL ANSWER:\")\n",
    "        print(f\"{'='*60}\")\n",
    "        print(self.current_answer)\n",
    "        print(f\"{'='*60}\\n\")\n",
    "        \n",
    "        return self.current_answer\n",
    "    \n",
    "    def perceive(self) -> Dict:\n",
    "        \"\"\"Gather current context\"\"\"\n",
    "        context = {\n",
    "            \"question\": self.current_question,\n",
    "            \"current_answer\": self.current_answer,\n",
    "            \"iteration\": self.iteration\n",
    "        }\n",
    "        \n",
    "        self.episodic.log(\"perceive\", {\"iteration\": self.iteration})\n",
    "        print(f\"👁️  [PERCEIVE] Gathering context...\")\n",
    "        \n",
    "        return context\n",
    "    \n",
    "    def plan(self, context: Dict) -> Dict:\n",
    "        \"\"\"Decide what to do next\"\"\"\n",
    "        if context[\"current_answer\"] is None:\n",
    "            action = {\"type\": \"generate_answer\"}\n",
    "        else:\n",
    "            action = {\"type\": \"improve_answer\"}\n",
    "        \n",
    "        self.episodic.log(\"plan\", action)\n",
    "        print(f\"🧠 [PLAN] Action: {action['type']}\")\n",
    "        \n",
    "        return action\n",
    "    \n",
    "    def act(self, action: Dict) -> Dict:\n",
    "        \"\"\"Execute the planned action\"\"\"\n",
    "        if action[\"type\"] == \"generate_answer\":\n",
    "            result = self._generate_initial_answer()\n",
    "        else:\n",
    "            result = self._improve_answer()\n",
    "        \n",
    "        self.short_term.add({\"action\": action[\"type\"], \"success\": result[\"success\"]})\n",
    "        self.episodic.log(\"act\", {\"action_type\": action[\"type\"]})\n",
    "        \n",
    "        return result\n",
    "    \n",
    "    def _generate_initial_answer(self) -> Dict:\n",
    "        \"\"\"Generate the first answer\"\"\"\n",
    "        print(f\"⚡ [ACT] Generating initial answer...\")\n",
    "        \n",
    "        prompt = f\"Question: {self.current_question}\\n\\nProvide a clear and accurate answer.\"\n",
    "        answer = self.llm.complete(prompt)\n",
    "        self.current_answer = answer\n",
    "        \n",
    "        print(f\"✓ Generated answer ({len(answer)} chars)\")\n",
    "        \n",
    "        return {\"success\": True, \"answer\": answer}\n",
    "    \n",
    "    def _improve_answer(self) -> Dict:\n",
    "        \"\"\"Improve based on critique\"\"\"\n",
    "        print(f\"⚡ [ACT] Improving answer based on critique...\")\n",
    "        \n",
    "        recent = self.short_term.get()\n",
    "        last_critique = None\n",
    "        for item in reversed(recent):\n",
    "            if \"critique\" in item:\n",
    "                last_critique = item[\"critique\"]\n",
    "                break\n",
    "        \n",
    "        prompt = f\"\"\"Question: {self.current_question}\n",
    "Current Answer: {self.current_answer}\n",
    "Critique: {last_critique}\n",
    "\n",
    "Improve the answer based on the critique.\"\"\"\n",
    "        \n",
    "        improved = self.llm.complete(prompt)\n",
    "        self.current_answer = improved\n",
    "        \n",
    "        print(f\"✓ Improved answer ({len(improved)} chars)\")\n",
    "        \n",
    "        return {\"success\": True, \"answer\": improved}\n",
    "    \n",
    "    def reflect(self, result: Dict):\n",
    "        \"\"\"Evaluate and decide next steps\"\"\"\n",
    "        print(f\"🤔 [REFLECT] Evaluating quality...\")\n",
    "        \n",
    "        critique_prompt = f\"\"\"Question: {self.current_question}\n",
    "Answer: {self.current_answer}\n",
    "\n",
    "Critically evaluate this answer:\n",
    "1. Is it accurate?\n",
    "2. Is it complete?\n",
    "3. What could be improved?\n",
    "\n",
    "Rate quality 1-10. Format: Quality: [score]/10\"\"\"\n",
    "        \n",
    "        critique = self.llm.complete(critique_prompt)\n",
    "        \n",
    "        self.short_term.add({\"critique\": critique})\n",
    "        self.episodic.log(\"reflect\", {\"iteration\": self.iteration})\n",
    "        \n",
    "        print(f\"📊 Critique: {critique[:60]}...\")\n",
    "        \n",
    "        if \"9\" in critique or \"10\" in critique:\n",
    "            self.satisfied = True\n",
    "            print(f\"✅ [REFLECT] Satisfied with quality!\")\n",
    "        elif self.iteration >= self.max_iterations:\n",
    "            print(f\"⏱️  [REFLECT] Max iterations reached\")\n",
    "        else:\n",
    "            print(f\"🔄 [REFLECT] Will improve in next iteration\")\n",
    "    \n",
    "    def get_session_summary(self) -> str:\n",
    "        return self.episodic.get_summary()\n",
    "\n",
    "print(\"✅ ReflectionAgent class created!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44ba34bd",
   "metadata": {},
   "source": [
    "## Part 4: Test Your Agent!\n",
    "\n",
    "Now let's create an agent and run it with a test question."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6d0bfcfc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "🎯 QUESTION: What is the difference between a language model and an AI agent?\n",
      "============================================================\n",
      "\n",
      "────────────────────────────────────────────────────────────\n",
      "🔄 ITERATION 1/3\n",
      "────────────────────────────────────────────────────────────\n",
      "👁️  [PERCEIVE] Gathering context...\n",
      "🧠 [PLAN] Action: generate_answer\n",
      "⚡ [ACT] Generating initial answer...\n",
      "\n",
      "💭 [LLM CALL #1]\n",
      "Prompt preview: Question: What is the difference between a language model and an AI agent?\n",
      "\n",
      "Prov...\n",
      "✓ Generated answer (92 chars)\n",
      "🤔 [REFLECT] Evaluating quality...\n",
      "\n",
      "💭 [LLM CALL #2]\n",
      "Prompt preview: Question: What is the difference between a language model and an AI agent?\n",
      "Answe...\n",
      "📊 Critique: Quality: 7/10. The answer is decent but could be more detail...\n",
      "✅ [REFLECT] Satisfied with quality!\n",
      "\n",
      "============================================================\n",
      "✅ FINAL ANSWER:\n",
      "============================================================\n",
      "A language model responds to prompts. An AI agent can autonomously pursue goals using tools.\n",
      "============================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create agent instance\n",
    "agent = ReflectionAgent(llm, max_iterations=3)\n",
    "\n",
    "# Test question\n",
    "question = \"What is the difference between a language model and an AI agent?\"\n",
    "\n",
    "# Run it!\n",
    "final_answer = agent.run(question)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07d536e7",
   "metadata": {},
   "source": [
    "## View Session Summary\n",
    "\n",
    "See how many actions the agent took and what happened."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "455b670d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📊 SESSION SUMMARY\n",
      "============================================================\n",
      "Total actions: 4\n",
      "  - perceive: 1\n",
      "  - plan: 1\n",
      "  - act: 1\n",
      "  - reflect: 1\n",
      "\n",
      "\n",
      "Total LLM calls: 2\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n📊 SESSION SUMMARY\")\n",
    "print(\"=\"*60)\n",
    "print(agent.get_session_summary())\n",
    "print(f\"\\nTotal LLM calls: {llm.call_count}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5191ce49",
   "metadata": {},
   "source": [
    "## Part 5: Save Session to File\n",
    "\n",
    "Export the agent's work to a JSON file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2de70376",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Session saved to my_first_agent_session.json\n"
     ]
    }
   ],
   "source": [
    "def save_session(agent, filename=\"agent_session.json\"):\n",
    "    \"\"\"Save agent session to JSON file\"\"\"\n",
    "    session_data = {\n",
    "        \"question\": agent.current_question,\n",
    "        \"final_answer\": agent.current_answer,\n",
    "        \"iterations\": agent.iteration,\n",
    "        \"history\": agent.episodic.get_history()\n",
    "    }\n",
    "    \n",
    "    with open(filename, 'w') as f:\n",
    "        json.dump(session_data, f, indent=2)\n",
    "    \n",
    "    print(f\"✅ Session saved to {filename}\")\n",
    "\n",
    "# Use it\n",
    "save_session(agent, \"my_first_agent_session.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e126f05",
   "metadata": {},
   "source": [
    "## 🎉 Congratulations!\n",
    "\n",
    "You've built your first complete AI agent!\n",
    "\n",
    "**What you accomplished:**\n",
    "- ✅ Implemented the agent loop (Perceive → Plan → Act → Reflect)\n",
    "- ✅ Added memory systems (short-term + episodic)\n",
    "- ✅ Created self-reflection capability\n",
    "- ✅ Built a working autonomous system\n",
    "\n",
    "**Next steps:**\n",
    "- Modify the questions and observe behavior\n",
    "- Try changing max_iterations\n",
    "- Add real LLM API calls (OpenAI/Anthropic)\n",
    "- Build more complex agents!\n",
    "\n",
    "**🎯 Challenges:**\n",
    "1. Add a confidence score to each answer\n",
    "2. Compare first vs final answer side-by-side\n",
    "3. Add more reflection criteria\n",
    "4. Make the agent handle follow-up questions"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
