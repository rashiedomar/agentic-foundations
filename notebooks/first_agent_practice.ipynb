{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45255ac4",
   "metadata": {},
   "outputs": [],
   "source": [
    "{\n",
    " \"cells\": [\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"# 🤖 Building Your First Agent - Practice Notebook\\n\",\n",
    "    \"\\n\",\n",
    "    \"This notebook guides you through building a Reflection Agent step-by-step.\\n\",\n",
    "    \"\\n\",\n",
    "    \"**What you'll build:** An agent that answers questions and improves its answers through self-reflection.\\n\",\n",
    "    \"\\n\",\n",
    "    \"## Setup\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# Imports\\n\",\n",
    "    \"from datetime import datetime\\n\",\n",
    "    \"from typing import List, Dict, Optional\\n\",\n",
    "    \"import json\\n\",\n",
    "    \"\\n\",\n",
    "    \"# If using OpenAI\\n\",\n",
    "    \"# !pip install openai\\n\",\n",
    "    \"# from openai import OpenAI\\n\",\n",
    "    \"\\n\",\n",
    "    \"# If using Anthropic\\n\",\n",
    "    \"# !pip install anthropic\\n\",\n",
    "    \"# from anthropic import Anthropic\\n\",\n",
    "    \"\\n\",\n",
    "    \"print(\\\"✅ Imports complete!\\\")\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## Part 1: Build Memory Systems\\n\",\n",
    "    \"\\n\",\n",
    "    \"First, let's create the memory components.\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"class ShortTermMemory:\\n\",\n",
    "    \"    \\\"\\\"\\\"Working memory for current task\\\"\\\"\\\"\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    def __init__(self, max_size: int = 5):\\n\",\n",
    "    \"        self.max_size = max_size\\n\",\n",
    "    \"        self.context = []\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    def add(self, item: Dict):\\n\",\n",
    "    \"        \\\"\\\"\\\"Add item to working memory\\\"\\\"\\\"\\n\",\n",
    "    \"        self.context.append(item)\\n\",\n",
    "    \"        \\n\",\n",
    "    \"        # Keep only recent items\\n\",\n",
    "    \"        if len(self.context) > self.max_size:\\n\",\n",
    "    \"            self.context = self.context[-self.max_size:]\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    def get(self) -> List[Dict]:\\n\",\n",
    "    \"        \\\"\\\"\\\"Get current context\\\"\\\"\\\"\\n\",\n",
    "    \"        return self.context\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    def clear(self):\\n\",\n",
    "    \"        \\\"\\\"\\\"Clear working memory\\\"\\\"\\\"\\n\",\n",
    "    \"        self.context = []\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Test it\\n\",\n",
    "    \"stm = ShortTermMemory(max_size=3)\\n\",\n",
    "    \"stm.add({\\\"step\\\": 1, \\\"action\\\": \\\"search\\\"})\\n\",\n",
    "    \"stm.add({\\\"step\\\": 2, \\\"action\\\": \\\"read\\\"})\\n\",\n",
    "    \"print(\\\"Short-term memory:\\\", stm.get())\\n\",\n",
    "    \"print(\\\"✅ Short-term memory works!\\\")\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"class EpisodicMemory:\\n\",\n",
    "    \"    \\\"\\\"\\\"Log of all actions and results\\\"\\\"\\\"\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    def __init__(self):\\n\",\n",
    "    \"        self.episodes = []\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    def log(self, action_type: str, details: Dict):\\n\",\n",
    "    \"        \\\"\\\"\\\"Log an action\\\"\\\"\\\"\\n\",\n",
    "    \"        episode = {\\n\",\n",
    "    \"            \\\"timestamp\\\": datetime.now().isoformat(),\\n\",\n",
    "    \"            \\\"action\\\": action_type,\\n\",\n",
    "    \"            \\\"details\\\": details\\n\",\n",
    "    \"        }\\n\",\n",
    "    \"        self.episodes.append(episode)\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    def get_history(self) -> List[Dict]:\\n\",\n",
    "    \"        \\\"\\\"\\\"Get all episodes\\\"\\\"\\\"\\n\",\n",
    "    \"        return self.episodes\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    def get_summary(self) -> str:\\n\",\n",
    "    \"        \\\"\\\"\\\"Summarize the session\\\"\\\"\\\"\\n\",\n",
    "    \"        summary = f\\\"Total actions: {len(self.episodes)}\\\\n\\\"\\n\",\n",
    "    \"        \\n\",\n",
    "    \"        action_counts = {}\\n\",\n",
    "    \"        for ep in self.episodes:\\n\",\n",
    "    \"            action = ep[\\\"action\\\"]\\n\",\n",
    "    \"            action_counts[action] = action_counts.get(action, 0) + 1\\n\",\n",
    "    \"        \\n\",\n",
    "    \"        for action, count in action_counts.items():\\n\",\n",
    "    \"            summary += f\\\"  - {action}: {count}\\\\n\\\"\\n\",\n",
    "    \"        \\n\",\n",
    "    \"        return summary\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Test it\\n\",\n",
    "    \"em = EpisodicMemory()\\n\",\n",
    "    \"em.log(\\\"perceive\\\", {\\\"context\\\": \\\"ready\\\"})\\n\",\n",
    "    \"em.log(\\\"plan\\\", {\\\"action\\\": \\\"search\\\"})\\n\",\n",
    "    \"print(\\\"Episodic memory:\\\", em.get_summary())\\n\",\n",
    "    \"print(\\\"✅ Episodic memory works!\\\")\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## Part 2: Create LLM Interface\\n\",\n",
    "    \"\\n\",\n",
    "    \"Choose your LLM provider and uncomment the appropriate section:\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# OPTION 1: Mock LLM (for testing without API)\\n\",\n",
    "    \"class SimpleLLM:\\n\",\n",
    "    \"    def __init__(self):\\n\",\n",
    "    \"        self.call_count = 0\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    def complete(self, prompt: str) -> str:\\n\",\n",
    "    \"        self.call_count += 1\\n\",\n",
    "    \"        print(f\\\"\\\\n[LLM CALL #{self.call_count}]\\\")\\n\",\n",
    "    \"        print(f\\\"Prompt: {prompt[:100]}...\\\")\\n\",\n",
    "    \"        \\n\",\n",
    "    \"        # Mock response\\n\",\n",
    "    \"        if \\\"critique\\\" in prompt.lower():\\n\",\n",
    "    \"            return \\\"Quality: 9/10. The answer is good but could be more concise.\\\"\\n\",\n",
    "    \"        else:\\n\",\n",
    "    \"            return \\\"This is a mock answer from the LLM. In reality, this would be a real response.\\\"\\n\",\n",
    "    \"\\n\",\n",
    "    \"llm = SimpleLLM()\\n\",\n",
    "    \"print(\\\"✅ Mock LLM ready (for testing)\\\")\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# OPTION 2: OpenAI (uncomment to use)\\n\",\n",
    "    \"# import os\\n\",\n",
    "    \"# from openai import OpenAI\\n\",\n",
    "    \"\\n\",\n",
    "    \"# class SimpleLLM:\\n\",\n",
    "    \"#     def __init__(self, model_name=\\\"gpt-4o-mini\\\"):\\n\",\n",
    "    \"#         self.client = OpenAI(api_key=os.getenv(\\\"OPENAI_API_KEY\\\"))\\n\",\n",
    "    \"#         self.model_name = model_name\\n\",\n",
    "    \"#         self.call_count = 0\\n\",\n",
    "    \"    \\n\",\n",
    "    \"#     def complete(self, prompt: str) -> str:\\n\",\n",
    "    \"#         self.call_count += 1\\n\",\n",
    "    \"#         print(f\\\"\\\\n[LLM CALL #{self.call_count}]\\\")\\n\",\n",
    "    \"        \\n\",\n",
    "    \"#         response = self.client.chat.completions.create(\\n\",\n",
    "    \"#             model=self.model_name,\\n\",\n",
    "    \"#             messages=[\\n\",\n",
    "    \"#                 {\\\"role\\\": \\\"system\\\", \\\"content\\\": \\\"You are a helpful assistant.\\\"},\\n\",\n",
    "    \"#                 {\\\"role\\\": \\\"user\\\", \\\"content\\\": prompt}\\n\",\n",
    "    \"#             ],\\n\",\n",
    "    \"#             temperature=0.7,\\n\",\n",
    "    \"#             max_tokens=1000\\n\",\n",
    "    \"#         )\\n\",\n",
    "    \"#         return response.choices[0].message.content\\n\",\n",
    "    \"\\n\",\n",
    "    \"# llm = SimpleLLM()\\n\",\n",
    "    \"# print(\\\"✅ OpenAI LLM ready\\\")\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## Part 3: Build the Agent\\n\",\n",
    "    \"\\n\",\n",
    "    \"Now let's create the complete Reflection Agent!\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"class ReflectionAgent:\\n\",\n",
    "    \"    \\\"\\\"\\\"Agent that improves answers through self-reflection\\\"\\\"\\\"\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    def __init__(self, llm, max_iterations: int = 3):\\n\",\n",
    "    \"        self.llm = llm\\n\",\n",
    "    \"        self.max_iterations = max_iterations\\n\",\n",
    "    \"        \\n\",\n",
    "    \"        # Memory systems\\n\",\n",
    "    \"        self.short_term = ShortTermMemory()\\n\",\n",
    "    \"        self.episodic = EpisodicMemory()\\n\",\n",
    "    \"        \\n\",\n",
    "    \"        # Agent state\\n\",\n",
    "    \"        self.current_question = None\\n\",\n",
    "    \"        self.current_answer = None\\n\",\n",
    "    \"        self.iteration = 0\\n\",\n",
    "    \"        self.satisfied = False\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    def run(self, question: str) -> str:\\n\",\n",
    "    \"        \\\"\\\"\\\"Main agent loop\\\"\\\"\\\"\\n\",\n",
    "    \"        self.current_question = question\\n\",\n",
    "    \"        self.iteration = 0\\n\",\n",
    "    \"        self.satisfied = False\\n\",\n",
    "    \"        \\n\",\n",
    "    \"        print(f\\\"\\\\n{'='*60}\\\")\\n\",\n",
    "    \"        print(f\\\"QUESTION: {question}\\\")\\n\",\n",
    "    \"        print(f\\\"{'='*60}\\\")\\n\",\n",
    "    \"        \\n\",\n",
    "    \"        while not self.satisfied and self.iteration < self.max_iterations:\\n\",\n",
    "    \"            self.iteration += 1\\n\",\n",
    "    \"            print(f\\\"\\\\n--- ITERATION {self.iteration} ---\\\")\\n\",\n",
    "    \"            \\n\",\n",
    "    \"            # THE AGENT LOOP\\n\",\n",
    "    \"            context = self.perceive()\\n\",\n",
    "    \"            action = self.plan(context)\\n\",\n",
    "    \"            result = self.act(action)\\n\",\n",
    "    \"            self.reflect(result)\\n\",\n",
    "    \"        \\n\",\n",
    "    \"        print(f\\\"\\\\n{'='*60}\\\")\\n\",\n",
    "    \"        print(f\\\"FINAL ANSWER:\\\\n{self.current_answer}\\\")\\n\",\n",
    "    \"        print(f\\\"{'='*60}\\\")\\n\",\n",
    "    \"        \\n\",\n",
    "    \"        return self.current_answer\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    def perceive(self) -> Dict:\\n\",\n",
    "    \"        \\\"\\\"\\\"Gather current context\\\"\\\"\\\"\\n\",\n",
    "    \"        context = {\\n\",\n",
    "    \"            \\\"question\\\": self.current_question,\\n\",\n",
    "    \"            \\\"current_answer\\\": self.current_answer,\\n\",\n",
    "    \"            \\\"iteration\\\": self.iteration\\n\",\n",
    "    \"        }\\n\",\n",
    "    \"        \\n\",\n",
    "    \"        self.episodic.log(\\\"perceive\\\", {\\\"iteration\\\": self.iteration})\\n\",\n",
    "    \"        print(f\\\"[PERCEIVE] Gathering context for iteration {self.iteration}\\\")\\n\",\n",
    "    \"        \\n\",\n",
    "    \"        return context\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    def plan(self, context: Dict) -> Dict:\\n\",\n",
    "    \"        \\\"\\\"\\\"Decide what to do next\\\"\\\"\\\"\\n\",\n",
    "    \"        if context[\\\"current_answer\\\"] is None:\\n\",\n",
    "    \"            action = {\\\"type\\\": \\\"generate_answer\\\"}\\n\",\n",
    "    \"        else:\\n\",\n",
    "    \"            action = {\\\"type\\\": \\\"improve_answer\\\"}\\n\",\n",
    "    \"        \\n\",\n",
    "    \"        self.episodic.log(\\\"plan\\\", action)\\n\",\n",
    "    \"        print(f\\\"[PLAN] Action: {action['type']}\\\")\\n\",\n",
    "    \"        \\n\",\n",
    "    \"        return action\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    def act(self, action: Dict) -> Dict:\\n\",\n",
    "    \"        \\\"\\\"\\\"Execute the planned action\\\"\\\"\\\"\\n\",\n",
    "    \"        if action[\\\"type\\\"] == \\\"generate_answer\\\":\\n\",\n",
    "    \"            result = self._generate_initial_answer()\\n\",\n",
    "    \"        else:\\n\",\n",
    "    \"            result = self._improve_answer()\\n\",\n",
    "    \"        \\n\",\n",
    "    \"        self.short_term.add({\\\"action\\\": action[\\\"type\\\"], \\\"success\\\": result[\\\"success\\\"]})\\n\",\n",
    "    \"        self.episodic.log(\\\"act\\\", {\\\"action_type\\\": action[\\\"type\\\"]})\\n\",\n",
    "    \"        \\n\",\n",
    "    \"        return result\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    def _generate_initial_answer(self) -> Dict:\\n\",\n",
    "    \"        \\\"\\\"\\\"Generate the first answer\\\"\\\"\\\"\\n\",\n",
    "    \"        print(f\\\"[ACT] Generating initial answer...\\\")\\n\",\n",
    "    \"        \\n\",\n",
    "    \"        prompt = f\\\"Question: {self.current_question}\\\\n\\\\nProvide a clear and accurate answer.\\\"\\n\",\n",
    "    \"        answer = self.llm.complete(prompt)\\n\",\n",
    "    \"        self.current_answer = answer\\n\",\n",
    "    \"        \\n\",\n",
    "    \"        print(f\\\"[ACT] Answer generated ({len(answer)} chars)\\\")\\n\",\n",
    "    \"        return {\\\"success\\\": True, \\\"answer\\\": answer}\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    def _improve_answer(self) -> Dict:\\n\",\n",
    "    \"        \\\"\\\"\\\"Improve based on critique\\\"\\\"\\\"\\n\",\n",
    "    \"        print(f\\\"[ACT] Improving answer...\\\")\\n\",\n",
    "    \"        \\n\",\n",
    "    \"        recent = self.short_term.get()\\n\",\n",
    "    \"        last_critique = None\\n\",\n",
    "    \"        for item in reversed(recent):\\n\",\n",
    "    \"            if \\\"critique\\\" in item:\\n\",\n",
    "    \"                last_critique = item[\\\"critique\\\"]\\n\",\n",
    "    \"                break\\n\",\n",
    "    \"        \\n\",\n",
    "    \"        prompt = f\\\"\\\"\\\"\\n\",\n",
    "    \"Question: {self.current_question}\\n\",\n",
    "    \"Current Answer: {self.current_answer}\\n\",\n",
    "    \"Critique: {last_critique}\\n\",\n",
    "    \"\\n\",\n",
    "    \"Improve the answer based on the critique.\\n\",\n",
    "    \"\\\"\\\"\\\"\\n\",\n",
    "    \"        \\n\",\n",
    "    \"        improved = self.llm.complete(prompt)\\n\",\n",
    "    \"        self.current_answer = improved\\n\",\n",
    "    \"        \\n\",\n",
    "    \"        print(f\\\"[ACT] Answer improved ({len(improved)} chars)\\\")\\n\",\n",
    "    \"        return {\\\"success\\\": True, \\\"answer\\\": improved}\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    def reflect(self, result: Dict):\\n\",\n",
    "    \"        \\\"\\\"\\\"Evaluate and decide next steps\\\"\\\"\\\"\\n\",\n",
    "    \"        print(f\\\"[REFLECT] Evaluating quality...\\\")\\n\",\n",
    "    \"        \\n\",\n",
    "    \"        critique_prompt = f\\\"\\\"\\\"\\n\",\n",
    "    \"Question: {self.current_question}\\n\",\n",
    "    \"Answer: {self.current_answer}\\n\",\n",
    "    \"\\n\",\n",
    "    \"Critically evaluate this answer:\\n\",\n",
    "    \"1. Is it accurate?\\n\",\n",
    "    \"2. Is it complete?\\n\",\n",
    "    \"3. What could be improved?\\n\",\n",
    "    \"\\n\",\n",
    "    \"Rate quality 1-10. Format: Quality: [score]/10\\n\",\n",
    "    \"\\\"\\\"\\\"\\n\",\n",
    "    \"        \\n\",\n",
    "    \"        critique = self.llm.complete(critique_prompt)\\n\",\n",
    "    \"        self.short_term.add({\\\"critique\\\": critique})\\n\",\n",
    "    \"        self.episodic.log(\\\"reflect\\\", {\\\"iteration\\\": self.iteration})\\n\",\n",
    "    \"        \\n\",\n",
    "    \"        # Check if satisfied\\n\",\n",
    "    \"        if \\\"9\\\" in critique or \\\"10\\\" in critique:\\n\",\n",
    "    \"            self.satisfied = True\\n\",\n",
    "    \"            print(f\\\"[REFLECT] ✅ Satisfied with quality!\\\")\\n\",\n",
    "    \"        elif self.iteration >= self.max_iterations:\\n\",\n",
    "    \"            print(f\\\"[REFLECT] ⏱️ Max iterations reached\\\")\\n\",\n",
    "    \"        else:\\n\",\n",
    "    \"            print(f\\\"[REFLECT] 🔄 Will improve in next iteration\\\")\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    def get_session_summary(self) -> str:\\n\",\n",
    "    \"        return self.episodic.get_summary()\\n\",\n",
    "    \"\\n\",\n",
    "    \"print(\\\"✅ ReflectionAgent class created!\\\")\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## Part 4: Test Your Agent!\\n\",\n",
    "    \"\\n\",\n",
    "    \"Now let's run it with different questions:\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# Create agent instance\\n\",\n",
    "    \"agent = ReflectionAgent(llm, max_iterations=3)\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Test question\\n\",\n",
    "    \"question = \\\"What is the difference between a language model and an AI agent?\\\"\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Run it!\\n\",\n",
    "    \"final_answer = agent.run(question)\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# View session summary\\n\",\n",
    "    \"print(\\\"\\\\nSESSION SUMMARY:\\\")\\n\",\n",
    "    \"print(agent.get_session_summary())\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## Part 5: Experiments\\n\",\n",
    "    \"\\n\",\n",
    "    \"Try different questions and observe how the agent improves:\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# Experiment 1: Simple question\\n\",\n",
    "    \"agent1 = ReflectionAgent(llm, max_iterations=2)\\n\",\n",
    "    \"agent1.run(\\\"What is Python?\\\")\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# Experiment 2: Complex question\\n\",\n",
    "    \"agent2 = ReflectionAgent(llm, max_iterations=3)\\n\",\n",
    "    \"agent2.run(\\\"Explain how neural networks learn\\\")\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# Experiment 3: Your own question!\\n\",\n",
    "    \"agent3 = ReflectionAgent(llm, max_iterations=3)\\n\",\n",
    "    \"my_question = \\\"YOUR QUESTION HERE\\\"\\n\",\n",
    "    \"agent3.run(my_question)\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## Part 6: Analysis\\n\",\n",
    "    \"\\n\",\n",
    "    \"Let's analyze how the agent performed:\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# Get full history\\n\",\n",
    "    \"history = agent.episodic.get_history()\\n\",\n",
    "    \"\\n\",\n",
    "    \"print(\\\"Full Episode History:\\\")\\n\",\n",
    "    \"for i, episode in enumerate(history, 1):\\n\",\n",
    "    \"    print(f\\\"\\\\n{i}. {episode['action']} at {episode['timestamp'][:19]}\\\")\\n\",\n",
    "    \"    print(f\\\"   Details: {episode['details']}\\\")\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# Count LLM calls\\n\",\n",
    "    \"print(f\\\"\\\\nTotal LLM calls made: {llm.call_count}\\\")\\n\",\n",
    "    \"print(f\\\"Cost estimate (if using GPT-4): ~${llm.call_count * 0.01:.2f}\\\")\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## 🎯 Your Challenges\\n\",\n",
    "    \"\\n\",\n",
    "    \"Try these modifications:\\n\",\n",
    "    \"\\n\",\n",
    "    \"1. **Add a confidence score** - Make the agent report how confident it is\\n\",\n",
    "    \"2. **Save to file** - Export the final answer and history to JSON\\n\",\n",
    "    \"3. **Compare iterations** - Show the difference between first and final answer\\n\",\n",
    "    \"4. **Add more reflection criteria** - Check for clarity, citations, examples\\n\",\n",
    "    \"5. **Multi-turn questions** - Let the agent handle follow-up questions\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# Challenge 1: Save session to file\\n\",\n",
    "    \"def save_session(agent, filename=\\\"agent_session.json\\\"):\\n\",\n",
    "    \"    \\\"\\\"\\\"Save agent session to JSON file\\\"\\\"\\\"\\n\",\n",
    "    \"    session_data = {\\n\",\n",
    "    \"        \\\"question\\\": agent.current_question,\\n\",\n",
    "    \"        \\\"final_answer\\\": agent.current_answer,\\n\",\n",
    "    \"        \\\"iterations\\\": agent.iteration,\\n\",\n",
    "    \"        \\\"history\\\": agent.episodic.get_history()\\n\",\n",
    "    \"    }\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    with open(filename, 'w') as f:\\n\",\n",
    "    \"        json.dump(session_data, f, indent=2)\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    print(f\\\"✅ Session saved to {filename}\\\")\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Use it\\n\",\n",
    "    \"save_session(agent, \\\"my_first_agent_session.json\\\")\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## 🎉 Congratulations!\\n\",\n",
    "    \"\\n\",\n",
    "    \"You've built your first complete AI agent! \\n\",\n",
    "    \"\\n\",\n",
    "    \"**What you accomplished:**\\n\",\n",
    "    \"- ✅ Implemented the agent loop (Perceive → Plan → Act → Reflect)\\n\",\n",
    "    \"- ✅ Added memory systems (short-term + episodic)\\n\",\n",
    "    \"- ✅ Created self-reflection capability\\n\",\n",
    "    \"- ✅ Built a working autonomous system\\n\",\n",
    "    \"\\n\",\n",
    "    \"**Next steps:**\\n\",\n",
    "    \"- Modify this agent for different tasks\\n\",\n",
    "    \"- Add tools (web search, calculator, etc.)\\n\",\n",
    "    \"- Build more complex agents\\n\",\n",
    "    \"- Explore multi-agent systems\"\n",
    "   ]\n",
    "  }\n",
    " ],\n",
    " \"metadata\": {\n",
    "  \"kernelspec\": {\n",
    "   \"display_name\": \"Python 3\",\n",
    "   \"language\": \"python\",\n",
    "   \"name\": \"python3\"\n",
    "  },\n",
    "  \"language_info\": {\n",
    "   \"codemirror_mode\": {\n",
    "    \"name\": \"ipython\",\n",
    "    \"version\": 3\n",
    "   },\n",
    "   \"file_extension\": \".py\",\n",
    "   \"mimetype\": \"text/x-python\",\n",
    "   \"name\": \"python\",\n",
    "   \"nbconvert_exporter\": \"python\",\n",
    "   \"pygments_lexer\": \"ipython3\",\n",
    "   \"version\": \"3.9.0\"\n",
    "  }\n",
    " },\n",
    " \"nbformat\": 4,\n",
    " \"nbformat_minor\": 4\n",
    "}"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
